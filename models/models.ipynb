{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy import optimize\n",
    "\n",
    "SEED = 333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/team_A_dataset.csv')\n",
    "\n",
    "seasonal_cols = ['avg_monthly_salary', 'general_thefts', 'break_in_thefts', 'noveHlaseniUchazeci',\n",
    "                  'absolventiSkolAMladistvi', 'noveHlasenaAUvolnenaVPM', 'obsazenaAZrusenaVPM']\n",
    "\n",
    "for col in seasonal_cols:\n",
    "    df[col + '_prev_year'] = df[col].shift(168)\n",
    "\n",
    "#fill previous year columns for 2009 with 2009 year values\n",
    "for i in range(len(df)):\n",
    "    for col in seasonal_cols:\n",
    "        if np.isnan(df.loc[df.index[i], col + '_prev_year']):\n",
    "            df.loc[df.index[i], col + '_prev_year'] = df.loc[df.index[i], col]\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")\n",
    "\n",
    "obj_cols = df.select_dtypes('object')\n",
    "encoder.fit(obj_cols)\n",
    "transformed_cols = encoder.transform(obj_cols).toarray()\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "transformed_df = pd.DataFrame(\n",
    "    transformed_cols, index=df.index, columns=feature_names).astype(bool)\n",
    "df = pd.concat(\n",
    "    [df.select_dtypes(exclude='object'), transformed_df], axis=1)\n",
    "\n",
    "obj_cols = df.select_dtypes('bool').columns\n",
    "df[obj_cols] = df[obj_cols].astype(int)\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "drop_cols = [f\"celkem_w{w}\" for w in range(2,20)]\n",
    "drop_cols += [f\"m_do_65_w{w}\" for w in range(2,19)]\n",
    "drop_cols += [f\"z_do_65_w{w}\" for w in range(2,19)]\n",
    "drop_cols += [f\"m_do_65_w{w}_ratio\" for w in range(2,19)]\n",
    "drop_cols += [f\"z_do_65_w{w}_ratio\" for w in range(2,19)]\n",
    "\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "#Since March 2022\n",
    "war_df = df.iloc[(158*14):, :]\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_tscv(tscv: TimeSeriesSplit, alpha: float, X, y, weights, verbose: bool = True):\n",
    "    rmses = []\n",
    "    maes = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        scaler = StandardScaler()\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_train = scaler.fit_transform(X.iloc[train_index, :])\n",
    "            X_test = scaler.transform(X.iloc[test_index, :])\n",
    "        else:\n",
    "            X_train = scaler.fit_transform(X[train_index, :])\n",
    "            X_test = scaler.transform(X[test_index, :])\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        model = Lasso(alpha=alpha, random_state=SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        if verbose:\n",
    "            print(\"pred\", model.predict(X_test),\n",
    "                  \"test:\", y_test, \"rmse\", rmse, \"mae\", mae)\n",
    "            print(model.coef_)\n",
    "            print(model.intercept_)\n",
    "            print()\n",
    "        rmses.append(rmse)\n",
    "        maes.append(mae)\n",
    "\n",
    "    weighted_rmse = np.average(rmses, weights=weights)\n",
    "    weighted_mae = np.average(maes, weights=weights)\n",
    "    sum_weighted_rmse = np.sum(rmses * weights)\n",
    "    sum_weighted_mae = np.sum(maes * weights)\n",
    "    print(\"rmse\", weighted_rmse)\n",
    "    print(\"mae\", weighted_mae)\n",
    "    print(\"sum weighted rmse\", sum_weighted_rmse)\n",
    "    print(\"sum weighted mae\", sum_weighted_mae)\n",
    "\n",
    "    return [weighted_rmse, weighted_mae, sum_weighted_rmse, sum_weighted_mae, model.coef_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since start of the war refugees predictors present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"celkem\", \"m_do_65\", \"z_do_65\",\"m_do_65_ratio\", \"z_do_65_ratio\", \"uchazeciOZamestnaniUoZ\",\t\"uchazeciOZamestnaniUoZZeny_ratio\", \"uchazeciOZamestnaniUoZMuzi\", \"uchazeciOZamestnaniUoZMuzi_ratio\"]\n",
    "df_war_refugees = war_df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kraje = 14\n",
    "n_splits = int(len(df_war_refugees)/n_kraje - 1)\n",
    "\n",
    "X = df_war_refugees.loc[:, df_war_refugees.columns != 'uchazeciOZamestnaniUoZZeny'].to_numpy()\n",
    "y = df_war_refugees.loc[:, df_war_refugees.columns == 'uchazeciOZamestnaniUoZZeny'].to_numpy()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits, test_size=n_kraje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization terminated successfully;\n",
      "The returned value satisfies the termination criteria\n",
      "(using xtol =  1e-05 )\n",
      "Best alpha 1.2296425808728362\n"
     ]
    }
   ],
   "source": [
    "weights = np.ones((18,))\n",
    "\n",
    "def optimize_alpha(alpha):\n",
    "    rmses = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X[train_index, :])\n",
    "        X_test = scaler.transform(X[test_index, :])\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        model = Lasso(alpha=alpha, random_state=SEED, max_iter=100000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.average(rmses, weights=weights)\n",
    "\n",
    "\n",
    "res = optimize.minimize_scalar(\n",
    "    optimize_alpha, bounds=(0, 1000), options={\"disp\": True})\n",
    "best_alpha = res.x\n",
    "print(f\"Best alpha {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 484.2213523318167\n",
      "mae 385.039490933605\n",
      "sum weighted rmse 5837.633957648342\n",
      "sum weighted mae 4641.9258392582715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.154e+04, tolerance: 4.033e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.459e+05, tolerance: 8.020e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.455e+05, tolerance: 1.190e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.713e+05, tolerance: 1.574e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.433e+05, tolerance: 1.992e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.596e+05, tolerance: 2.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.333e+05, tolerance: 2.950e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e+06, tolerance: 3.420e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+06, tolerance: 3.878e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "q = 0.95\n",
    "exps = np.linspace(0, n_splits-1, num=n_splits)\n",
    "weights = np.flip(np.power(q, exps))\n",
    "\n",
    "results.append(eval_tscv(tscv, best_alpha, X, y, weights, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since start of the war no refugee predictors present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"m_do_65_w19\"]\n",
    "drop_cols += [\"z_do_65_w19\"]\n",
    "drop_cols += [\"m_do_65_w19_ratio\"]\n",
    "drop_cols += [\"z_do_65_w19_ratio\"]\n",
    "drop_cols += [\"celkem\", \"m_do_65\", \"z_do_65\",\"m_do_65_ratio\", \"z_do_65_ratio\", \"uchazeciOZamestnaniUoZ\", \"uchazeciOZamestnaniUoZZeny_ratio\", \"uchazeciOZamestnaniUoZMuzi\", \"uchazeciOZamestnaniUoZMuzi_ratio\"]\n",
    "df_war_no_refugees = war_df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kraje = 14\n",
    "n_splits = int(len(war_df)/n_kraje - 1)\n",
    "\n",
    "X = df_war_no_refugees.loc[:, df_war_no_refugees.columns != 'uchazeciOZamestnaniUoZZeny'].to_numpy()\n",
    "y = df_war_no_refugees.loc[:, df_war_no_refugees.columns == 'uchazeciOZamestnaniUoZZeny'].to_numpy()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits, test_size=n_kraje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization terminated successfully;\n",
      "The returned value satisfies the termination criteria\n",
      "(using xtol =  1e-05 )\n",
      "Best alpha 2.5822215535124333\n"
     ]
    }
   ],
   "source": [
    "weights = np.ones((18,))\n",
    "\n",
    "def optimize_alpha(alpha):\n",
    "    rmses = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X[train_index, :])\n",
    "        X_test = scaler.transform(X[test_index, :])\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        model = Lasso(alpha=alpha, random_state=SEED, max_iter=1000000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.average(rmses, weights=weights)\n",
    "\n",
    "\n",
    "res = optimize.minimize_scalar(\n",
    "    optimize_alpha, bounds=(0, 1000), options={\"disp\": True})\n",
    "best_alpha = res.x\n",
    "print(f\"Best alpha {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 617.4287521848557\n",
      "mae 503.4913659396094\n",
      "sum weighted rmse 7443.5442237847965\n",
      "sum weighted mae 6069.947723366196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+05, tolerance: 4.033e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e+05, tolerance: 8.020e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.667e+05, tolerance: 1.190e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.207e+05, tolerance: 1.574e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e+05, tolerance: 1.992e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/david/.local/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.531e+05, tolerance: 2.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "q = 0.95\n",
    "exps = np.linspace(0, n_splits-1, num=n_splits)\n",
    "weights = np.flip(np.power(q, exps))\n",
    "\n",
    "results.append(eval_tscv(tscv, best_alpha, X, y, weights, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire period refugee predictors present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"celkem\", \"m_do_65\", \"z_do_65\",\"m_do_65_ratio\", \"z_do_65_ratio\", \"uchazeciOZamestnaniUoZ\",\t\"uchazeciOZamestnaniUoZZeny_ratio\", \"uchazeciOZamestnaniUoZMuzi\", \"uchazeciOZamestnaniUoZMuzi_ratio\"]\n",
    "df_entire_refugees = df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kraje = 14\n",
    "n_splits = int(len(war_df)/n_kraje - 1)\n",
    "\n",
    "X = df_entire_refugees.loc[:, df_entire_refugees.columns != 'uchazeciOZamestnaniUoZZeny'].to_numpy()\n",
    "y = df_entire_refugees.loc[:, df_entire_refugees.columns == 'uchazeciOZamestnaniUoZZeny'].to_numpy()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits, test_size=n_kraje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization terminated successfully;\n",
      "The returned value satisfies the termination criteria\n",
      "(using xtol =  1e-05 )\n",
      "Best alpha 298.7685511573443\n"
     ]
    }
   ],
   "source": [
    "weights = np.ones((18,))\n",
    "\n",
    "def optimize_alpha(alpha):\n",
    "    rmses = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X[train_index, :])\n",
    "        X_test = scaler.transform(X[test_index, :])\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        model = Lasso(alpha=alpha, random_state=SEED, max_iter=1000000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.average(rmses, weights=weights)\n",
    "\n",
    "\n",
    "res = optimize.minimize_scalar(\n",
    "    optimize_alpha, bounds=(0, 1000), options={\"disp\": True})\n",
    "best_alpha = res.x\n",
    "print(f\"Best alpha {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 1486.0419447387428\n",
      "mae 1079.2178589744315\n",
      "sum weighted rmse 17915.29612918034\n",
      "sum weighted mae 13010.741453079292\n"
     ]
    }
   ],
   "source": [
    "q = 0.95\n",
    "exps = np.linspace(0, n_splits-1, num=n_splits)\n",
    "weights = np.flip(np.power(q, exps))\n",
    "\n",
    "results.append(eval_tscv(tscv, best_alpha, X, y, weights, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire period no refugee predictors present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"m_do_65_w19\"]\n",
    "drop_cols += [\"z_do_65_w19\"]\n",
    "drop_cols += [\"m_do_65_w19_ratio\"]\n",
    "drop_cols += [\"z_do_65_w19_ratio\"]\n",
    "drop_cols += [\"celkem\", \"m_do_65\", \"z_do_65\",\"m_do_65_ratio\", \"z_do_65_ratio\", \"uchazeciOZamestnaniUoZ\",\t\"uchazeciOZamestnaniUoZZeny_ratio\", \"uchazeciOZamestnaniUoZMuzi\", \"uchazeciOZamestnaniUoZMuzi_ratio\"]\n",
    "df_entire_no_refugees = df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kraje = 14\n",
    "n_splits = int(len(war_df)/n_kraje - 1)\n",
    "\n",
    "X = df_entire_no_refugees.loc[:, df_entire_no_refugees.columns != 'uchazeciOZamestnaniUoZZeny'].to_numpy()\n",
    "y = df_entire_no_refugees.loc[:, df_entire_no_refugees.columns == 'uchazeciOZamestnaniUoZZeny'].to_numpy()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits, test_size=n_kraje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization terminated successfully;\n",
      "The returned value satisfies the termination criteria\n",
      "(using xtol =  1e-05 )\n",
      "Best alpha 298.76529218494517\n"
     ]
    }
   ],
   "source": [
    "weights = np.ones((18,))\n",
    "\n",
    "def optimize_alpha(alpha):\n",
    "    rmses = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X[train_index, :])\n",
    "        X_test = scaler.transform(X[test_index, :])\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        model = Lasso(alpha=alpha, random_state=SEED, max_iter=1000000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.average(rmses, weights=weights)\n",
    "\n",
    "\n",
    "res = optimize.minimize_scalar(\n",
    "    optimize_alpha, bounds=(0, 1000), options={\"disp\": True})\n",
    "best_alpha = res.x\n",
    "print(f\"Best alpha {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 1486.0419344342226\n",
      "mae 1079.219964426055\n",
      "sum weighted rmse 17915.296004951997\n",
      "sum weighted mae 13010.766835801129\n"
     ]
    }
   ],
   "source": [
    "q = 0.95\n",
    "exps = np.linspace(0, n_splits-1, num=n_splits)\n",
    "weights = np.flip(np.power(q, exps))\n",
    "\n",
    "results.append(eval_tscv(tscv, best_alpha, X, y, weights, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since start of the war with refugees:\n",
      "rmse 484.2213523318167\n",
      "mae 385.039490933605\n",
      "sum weighted rmse 5837.633957648342\n",
      "sum weighted mae 4641.9258392582715\n",
      "support size 38\n",
      "useful features ['month', 'year', 'break_in_thefts', 'avg_monthly_salary', 'm_do_65_w19', 'z_do_65_w19', 'monthly_min_wage', 'monthly_inflation_rate_wrt_last_year', 'reer', 'm_do_65_w19_ratio', 'z_do_65_w19_ratio', 'bilance', 'avg_energy_price', 'avg_gasoline_price', 'avg_natural_gas_price', 'noveHlaseniUchazeci', 'noveHlasenaAUvolnenaVPM', 'obsazenaAZrusenaVPM', 'absolventiSkolAMladistvi', 'avg_monthly_salary_prev_year', 'general_thefts_prev_year', 'break_in_thefts_prev_year', 'noveHlaseniUchazeci_prev_year', 'absolventiSkolAMladistvi_prev_year', 'obsazenaAZrusenaVPM_prev_year', 'kraj_JHC', 'kraj_JHM', 'kraj_KVK', 'kraj_LBK', 'kraj_MSK', 'kraj_OLK', 'kraj_PAK', 'kraj_PHA', 'kraj_PLK', 'kraj_STC', 'kraj_ULK', 'kraj_VYS', 'kraj_ZLK']\n",
      "\n",
      "Since start of the war no refugees:\n",
      "rmse 617.4287521848557\n",
      "mae 503.4913659396094\n",
      "sum weighted rmse 7443.5442237847965\n",
      "sum weighted mae 6069.947723366196\n",
      "support size 31\n",
      "useful features ['month', 'year', 'break_in_thefts', 'monthly_min_wage', 'monthly_inflation_rate_wrt_last_year', 'reer', 'bilance', 'avg_energy_price', 'avg_gasoline_price', 'avg_natural_gas_price', 'noveHlaseniUchazeci', 'noveHlasenaAUvolnenaVPM', 'obsazenaAZrusenaVPM', 'absolventiSkolAMladistvi', 'general_thefts_prev_year', 'noveHlaseniUchazeci_prev_year', 'absolventiSkolAMladistvi_prev_year', 'noveHlasenaAUvolnenaVPM_prev_year', 'kraj_JHC', 'kraj_JHM', 'kraj_KVK', 'kraj_LBK', 'kraj_MSK', 'kraj_OLK', 'kraj_PAK', 'kraj_PHA', 'kraj_PLK', 'kraj_STC', 'kraj_ULK', 'kraj_VYS', 'kraj_ZLK']\n",
      "\n",
      "Entire period with refugees:\n",
      "rmse 1486.0419447387428\n",
      "mae 1079.2178589744315\n",
      "sum weighted rmse 17915.29612918034\n",
      "sum weighted mae 13010.741453079292\n",
      "support size 15\n",
      "useful features ['month', 'break_in_thefts', 'reer', 'noveHlaseniUchazeci', 'absolventiSkolAMladistvi', 'break_in_thefts_prev_year', 'noveHlaseniUchazeci_prev_year', 'absolventiSkolAMladistvi_prev_year', 'kraj_JHM', 'kraj_MSK', 'kraj_PAK', 'kraj_PHA', 'kraj_STC', 'kraj_ULK', 'kraj_VYS']\n",
      "\n",
      "Entire period no refugees:\n",
      "rmse 1486.0419344342226\n",
      "mae 1079.219964426055\n",
      "sum weighted rmse 17915.296004951997\n",
      "sum weighted mae 13010.766835801129\n",
      "support size 15\n",
      "useful features ['month', 'break_in_thefts', 'reer', 'noveHlaseniUchazeci', 'absolventiSkolAMladistvi', 'break_in_thefts_prev_year', 'noveHlaseniUchazeci_prev_year', 'absolventiSkolAMladistvi_prev_year', 'kraj_JHM', 'kraj_MSK', 'kraj_PAK', 'kraj_PHA', 'kraj_STC', 'kraj_ULK', 'kraj_VYS']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_labels = [\"Since start of the war with refugees\",\n",
    "                \"Since start of the war no refugees\",\n",
    "                \"Entire period with refugees\", \n",
    "                \"Entire period no refugees\"]\n",
    "\n",
    "dfs = [df_war_refugees.drop(columns=\"uchazeciOZamestnaniUoZZeny\"),\n",
    "       df_war_no_refugees.drop(columns=\"uchazeciOZamestnaniUoZZeny\"),\n",
    "       df_entire_refugees.drop(columns=\"uchazeciOZamestnaniUoZZeny\"),\n",
    "       df_war_no_refugees.drop(columns=\"uchazeciOZamestnaniUoZZeny\")]\n",
    "\n",
    "feature_sel_eps = 1e-6\n",
    "\n",
    "for i in range(len(model_labels)):\n",
    "    print(model_labels[i] + \":\")\n",
    "    weighted_rmse, weighted_mae, sum_weighted_rmse, sum_weighted_mae, coefs = results[i]\n",
    "    print(\"rmse\", weighted_rmse)\n",
    "    print(\"mae\", weighted_mae)\n",
    "    print(\"sum weighted rmse\", sum_weighted_rmse)\n",
    "    print(\"sum weighted mae\", sum_weighted_mae)\n",
    "    print(\"support size\", np.sum((np.abs(np.array(coefs)) > feature_sel_eps).astype(int)))\n",
    "    print(\"useful features\", dfs[i].columns[np.abs(np.array(coefs)) > feature_sel_eps].to_list())\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
